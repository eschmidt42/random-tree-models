{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://medium.com/@penggongting/implementing-decision-tree-from-scratch-in-python-c732e7c69aea\n",
    "* https://www.kdnuggets.com/2020/01/decision-tree-algorithm-explained.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The core algorithm aka the CART algorithm\n",
    "\n",
    "CART = Classification And Regression Tree\n",
    "\n",
    "Starting with a tabular dataset we have columns / features and rows / observations. Each row has a target value, of which either all are continuous or categorical. \n",
    "\n",
    "Taking a subset of the observations as a training set, the algorithm iterates:\n",
    "\n",
    "1. select a feature\n",
    "2. select a range of thresholds (e.g. the feature values in the taining set) \n",
    "3. for each threshold\n",
    "    * create two groups of observations, one below the threshold and one above and \n",
    "    * evaluate the split score\n",
    "4. select the threshold with the optimal split score (here that always means largest)\n",
    "5. select the related group split \n",
    "6. continue from 1. for each group whose target values are not yet homogeneous (e.g. not all the same class, or the standard variation is greater than zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.datasets as sk_datasets\n",
    "\n",
    "from random_tree_models.models.decisiontree import (\n",
    "    DecisionTreeClassifier,\n",
    "    DecisionTreeRegressor,\n",
    ")\n",
    "from random_tree_models.models.decisiontree.visualize import show_tree\n",
    "from random_tree_models.scoring import MetricNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "split score:\n",
    "* gini\n",
    "* entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_datasets.make_classification(\n",
    "    n_samples=1_000,\n",
    "    n_features=2,\n",
    "    n_classes=2,\n",
    "    n_redundant=0,\n",
    "    class_sep=2,\n",
    "    random_state=rng,\n",
    ")\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, alpha=0.3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(measure_name=MetricNames.gini, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X)\n",
    "y_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_plot)[:, 1]\n",
    "y_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_prob.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "split score:\n",
    "\n",
    "* variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, coefs = sk_datasets.make_regression(\n",
    "    n_samples=1_000, n_features=2, n_targets=1, coef=True, random_state=rng\n",
    ")\n",
    "sns.scatterplot(x=X[:, 0], y=y, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(measure_name=MetricNames.variance, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_plot)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(12, 6))\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(x=X_plot[:, 0], y=y_pred, ax=ax, alpha=0.1, label=\"prediction\")\n",
    "\n",
    "ax = axs[1]\n",
    "sns.scatterplot(x=X_plot[:, 1], y=y_pred, ax=ax, alpha=0.1, label=\"prediction\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_pred.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(12, 6))\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(x=X[:, 0], y=y_pred, ax=ax, alpha=0.1, label=\"prediction\")\n",
    "sns.scatterplot(x=X[:, 0], y=y, ax=ax, alpha=0.1, label=\"actual\")\n",
    "\n",
    "ax = axs[1]\n",
    "sns.scatterplot(x=X[:, 1], y=y_pred, ax=ax, alpha=0.1, label=\"prediction\")\n",
    "sns.scatterplot(x=X[:, 1], y=y, ax=ax, alpha=0.1, label=\"actual\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
